%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Angaben zur Person
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\name}{Dennis Pidun}
\newcommand{\matr}{??????}
\newcommand{\email}{pidund@uni-hildesheim.de}
\newcommand{\studgang}{Angewandte Informatik (B.Sc.)}
\newcommand{\thema}{Safety Engineering in AGI}
\newcommand{\keywords}{}
\newcommand{\betreuer}{Dr. Pascal Reuß}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Angaben zum Seminar
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\semester}{Wintersemester 2019/2020}
\newcommand{\vtyp}{Seminar}
\newcommand{\veranstaltung}{IIS Seminar}
\newcommand{\prof}{Prof. Dr. Klaus-Dieter Althoff}
\newcommand{\lehrstuhl}{Institut für Informatik\\Bereich Intelligente Informationssysteme}

\include{preamble}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Zusatzpakete
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
    \include{titelseite}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % Abstract etc.
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section*{Abstract}
    \begin{abstract}
        \textsl{
        Abstract einfügen.
        }
    \end{abstract}
    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % Inhaltsverzeichnis
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \tableofcontents

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % Inhalt
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \section{Einführung}
        \subsection{Motivation}
            Die Technologien im Bereich der künstlichen Intelligenz sind ständig im Wandel. Tag für Tag
            werden daher immer wieder neue Entdeckungen gemacht, welche es ermöglichen schwierige Probleme
            in simplen Schritten zu lösen. Dabei wird die Forschung ständig vor neuen Herausforderungen
            gestellt, nicht nur werden Abläufe und Prozesse immer schneller, es treten auch Probleme auf,
            welche es gilt zu identifizieren und im besten Fall vorzubeugen. Diese Arbeit zielt daher
            darauf ab Konzepte herauszufinden, welche es ermöglichen möglichst gezielt für Sicherheit
            in der Entwicklung von Artificial General Intelligence zu sorgen. Die Herausforderung eine
            sichere Umgebung sowohl für Mensch als auch für die Maschine aufzustellen, stellt somit das
            Kernthema dar. //TBC

        \subsection{Machine Ethics}
            //Überarbeiten//
            Um die Frage, warum Machine Ethics wichtig sind zu klären, stellen wir uns zunächst ein
            Scenario vor, welches bereits von Patrick Lin aufgestellt wurde. \cite[p. 70]{maurer_gerdes_lenz_winner_2015}
            Hierbei handelt es sich um eine Situation, welche bereits heute auf den
            Straßen auftreten kann. Um die moralischen Entscheidungen in dem Prozess des Fahrens zu
            verdeutlichen, stellen wir uns also vor, dass man in einem Auto sitzt und nun eine
            Entscheidung treffen muss. Nämlich die Entscheidung, ob man nach links ausweicht und damit
            ein junges Mädchen umbringt oder ob man nach rechts ausweicht und damit eine ältere
            Seniorin umbringt. Weicht man nicht aus, werden augenblicklich beide Menschen mit in den
            Tot gerissen. Dieses Beispiel ist tatsächlich sehr dramatisch gewählt, was jedoch sehr gut
            verdeutlicht, welche nicht rationalen Entscheidungen getroffen werden müssen. Egal welche
            Entscheidung hierbei getroffen wird, am Ende stirbt mindestens ein Mensch, was in jeder
            Hinsicht einen Verlust darstellt und ohnehin moralisch nicht korrekt wäre. \cite[p. 70]{maurer_gerdes_lenz_winner_2015}
            Mit seiner Entscheidung kann man letztendlich nur bestimmen, welche Person benachteiligt
            wird. In einer solchen Situation jedoch hätte der Mensch ohnehin keine Zeit diese Entscheidung
            rational zu betrachten. Ferner hätte der Mensch ebenfalls nicht die Möglichkeiten und
            das Wissen gerecht zu entscheiden.
            //Überarbeiten//

            Ein weiteres Problem ist außerdem, dass man nicht genau weiß, welche moralischen Werte man
            innerhalb der AGI verankern soll.\cite[p. 1]{yampolskiy2013safety} Es wird daher viel
            diskutiert, welche moralischen Wertvorstellungen die richtigen sind. In diversen Literaturen
            findet man unter verschiedenen Titeln immer wieder Diskussionen, welche sich genau mit dieser
            Fragestellung auseinandersetzen. Yampolskiy spricht hier davon, dass keine effektiven
            Maßnahmen getroffen werden, da sich einerseits viel damit beschäftigt wird, sich andererseits
            aber nichts wandelt und kein nutzbares Ergebnis herauskommt.\cite[p. 1]{yampolskiy2013safety}
            Dies greifen Yampolskiy und Fox nun auf, um über verschiedene Möglichkeiten dieses Problem zu
            lösen zu diskutieren.

            Laut Yampolskiy und Fox stellt man sich diese Fragen nicht nur bei near-human-AIs, sondern
            ebenso bei superintelligent AIs.\cite[p. 2]{yampolskiy2013safety} Es ist ferner deutlich
            bedeutender, so Fox und Yampolskiy, dass man sich gerade im Hinblick auf die immer schnelleren
            Fortschritte in AGIs, Gedanken um die Sicherheit und Moral bei superintelligent AIs macht.
            So gehen Crnkovic und {\c{C}}{\"u}r{\"u}kl{\"u} ebenfalls davon aus, dass die Betrachtung
            der Moral in superintelligent AIs eine übergeordnete Rolle haben muss.\cite[p. 1]{crnkovic2012robots}
            Sie sprechen hier davon, dass AIs genau das tun würden, wozu sie programmiert
            wurden, was jedoch nicht exakt richtig ist. Hierbei muss man nämlich zwischen simplen Agenten
            und komplexeren Agentensystemen unterscheiden, da mit steigender Komplexität und erhöter
            Autonomität die moralischen Herausforderungen ebenfalls ansteigen werden. Crnkovic et al
            stellen hier den folgenden Grundsatz auf: ``intelligence must come in conjunction with ethics,
            through the concept of an artifact ethical by design''. Um dies zu unterstützen, gehe ich daher
            auf die Möglichkeiten im Bereich des Safety Engineerings ein.

    \section{Artificial General Intelligence}
        Um besser differenzieren zu können, um welche Art von künstlicher Intelligenz hier behandelt
        wird, werde ich nachfolgend auf diverse Definitionen eingehen, welche sich mit den verschiedenen
        Stufen von AI(-Systemen) und deren Abgrenzung beschäftigen.

        \subsection{Classical Artificial Intelligence}\label{subsec:cai}
            John McCarthy stellte zu Beginn der Era der künstlichen Intelligenz bereits folgende Definition
            auf: ``Getting a computer to do things which, when done by people, are said to involve intelligence.''.
            \cite[p. 1]{ertel2016grundkurs} Dies ist jedoch eine sehr allgemeine Definition für das
            Verhalten von Maschinen, die über künstliche Intelligenz verfügen sollen. Daher stelle ich mir
            diverse Fragen dazu, unter Anderem: ``Was ist Intelligenz?'', ``Wie kann eine Maschine intelligentes
            Verhalten zeigen?'' und ``Wann gilt eine Maschine als intelligent?''. All diese Fragen sind die
            Grundlage für eine intelligente Maschine, welche eigenständig nach Lösungswegen für ein spezielles
            Problem suchen. Um dies zu testen, stellt Ertel folgende Situation auf: Man stelle sich ein Feld
            vor, auf dem Roboter wild um herzufahren scheinen. Einige folgen einander, andere weichen einander
            aus, wieder andere haben keine klaren Ziele. \cite[p. 2]{ertel2016grundkurs} Ertel stellt hier die
            Frage ``Sehen wir hier intelligentes Verhalten?'', wobei nach Definition von McCarthy hier von
            intelligentem Verhalten gesprochen werden kann. In \ref{pic:braitenberg-vehikel} sieht man zwei
            simple Verschaltungen dieser sogenannten Breitenberg-Vehikel. Dargestellt werden hier simple
            Verschaltungen von Sensoren zu Motoren, welche je nach Lichtstärke unterschiedlich reagieren.
            Man kann nun diskutieren, ob dieses Verhalten wirklich ein intelligentes Verhalten ist oder
            nur durch Zufall intelligent erscheint. Ertel behauptet daher, dass die obige Definition nicht
            ausreichend ist, da KI sich zum Ziel setzt, viele schwierige Probleme zu lösen. In diesem Beispiel
            wären die Braitenberg-Vehikel mit anderen komplexeren Situationen sichtlich überfordert.

            \begin{figure}[h]
                \begin{center}
                    \includegraphics[width=0.8\textwidth]{figures/braitenberg-roboter.png}
                    \caption[Verschaltung Braitenberg-Vehikel]{Simple Verschaltung zweier Braitenbergvehikel nach \cite{ertel2016grundkurs}}
                    \label{pic:braitenberg-vehikel}
                \end{center}
            \end{figure}

            Die Aussage von John McCarthy ist schlichtweg nicht genau genug und bestimmt nicht im Detail was
            genau Intelligenz bedeutet. Dabei besteht Intelligenz laut Shukla et al. aus zwei Grundkomponenten:
            Zunächst benötigt man die Fähigkeit neue Konzepte zu erlernen, sprich Informationen nicht nur
            aufzunehmen sondern auch zu verarbeiten und in Wissen umzuwandeln. Dieses Wissen muss außerdem
            korrekt angewendet werden, woraus insgesamt Schlussfolgerungen über die reale Welt gezogen werden
            können. \cite{shukla2013applicability} Bei den Braitenberg Vehikeln ist dies jedoch nicht der Fall,
            alles was sie tun ist eine Information - hier die Lichtstärke der Lichtquelle - aufnehmen und diese
            in mechanische Energie - also die Bewegung eines Motors - umzuwandeln. Man kann hier allerdings nicht
            von Wissen sprechen, da hier keine Informationen erlernt oder in irgendeiner Weise abgelegt werden.

            Um nun zu verstehen, warum man bei intelligenten Maschinen davon spricht, dass sie über eine
            künstliche Intelligenz verfügen, muss man sich vor Augen halten in welchen Gebieten diese Maschinen
            eingesetzt werden sollen. Unteranderem werden diese künstlichen Intelligenzen in Bereichen eingesetzt,
            wo es die Situation erfordert, dass die menschliche Intelligenz Unterstützung erfahren muss.\cite[p. 2]{ertel2016grundkurs}
            Diese Bereiche sind in jedem Fall speziell und nicht im Generellen zu verstehen. Bei künstlicher
            Intelligenz kann man daher festhalten, dass sie sich auf bestimmte Bereiche konzentriert und dort
            generalisierend wirkt. Elaine Rich hielt daher fest: ``Artificial Intelligence is the study of how
            to make computers do things at which, at the moment, people are better.''. Beispielsweise sind (normale)
            Computer sehr gut darin Berechnungen in Bruchteilen durchzuführen und diese zu Ergebnissen zu führen.\cite[p. 3]{ertel2016grundkurs}
            In anderen Bereichen schneiden dahingegen diese Computer wiederum schlecht ab. Abhilfe, so Ertel,
            könnten daher künstliche Intelligenzen in Form von neuronalen Netzen sein.

        \subsection{Verbindung zu ''Strong AI''}
            Viele Quellen berichten, dass man grundsätzlich zwischen Strong AI und Weak AI unterscheidet.\cite{huang_beef}
            Doch was sind die allgemeinen Kriterien, um eine Künstliche Intelligenz in die Kategorien \textit{Weak}
            und \textit{Strong} zu unterteilen?

            Schwache KIs sind, wie wir bereits in \ref{subsec:cai} kennengelernt haben, Systeme welche genau auf
            eine Anwendung hin konzipiert und trainiert wurden. Diese schwachen Systeme beziehungsweise schwach
            intelligente Maschinen stellen dabei den Großteil in der aktuellen Entwicklung dar. \cite{brendel_2019}
            Aber wie groß ist der Schritt, um von einer Weak, beziehungsweise schwachen KI zu einer Strong,
            beziehungsweise starken KI zu gelangen?

            Unter strong AI kann man zunächst ebenfalls broad oder general AI verstehen.\cite{walch_world_2019}
            Es wird daher davon ausgegangen, dass eine general AI dazu in der Lage ist, jegliche Herausforderung,
            die von einem Menschen gemeistert werden kann, ebenfalls von einer Maschine übernommen werden kann.
            Dabei unterscheidet Walch drei Aspekte: ``(1) the ability to generalize knowledge from one domain to
            another'', ``(2) the ability to make plans for the future based on knowledge and experiences'' und
            ``(3) the ability to adapt to the environment as changes occur''. Gemeint sind hier unteranderem,
            dass eine AGI Transferleistung erbringen können muss, beispielsweise muss es Informationen aufnehmen
            können und diese auf ein anderes Problem übertragen können. Man spricht hier von unterschiedlichen
            Domänen, sozusagen unterschiedliche Einsatzgebiete, die wiederum nichts weiter miteinander zutun
            haben. \cite{walch_world_2019} Weiter wird beschrieben, dass eine AGI Pläne machen können muss,
            welche in der Zukunft umgesetzt werden. Somit muss eine AGI Informationen behalten können und diese
            in der Zukunft verwerten können. Der letzte Punkt spricht die Anpassbarkeit an, welche benötigt
            wird, dass eine AI als AGI zählen kann. All diese Punkte sprechen daher die Kernunterschiede zwischen
            einer weak und einer strong AI an, zu welchen noch folgende Grundkriterien hinzukommen:
            \textit{ability to reason}, \textit{solve puzzles}, \textit{represent knowledge and common sense} und
            \textit{ability to plan}.

            Walch et al. stellen hier die Frage auf, ob diese Kriterien ausreichen, um zwischen Weak und Strong AI
            zu unterscheiden und kommen zu dem Schluss, dass einfache Kommunikation und das Abarbeiten von
            speziellen Aufgaben nicht in Verbindung mit dem Term ``Strong AI'' stehen. Daher könnte man beispielsweise
            bereits einfache Chatbots als AGI-Systeme bezeichnen. \cite{walch_world_2019} Dabei besteht die
            Möglichkeit einen einfachen Turing Test durchzuführen, doch führt das zu dem Ergebnis, dass eine
            Maschine wirklich eine stark intelligente Maschine ist, oder nicht?
            \begin{figure}[h]
                \begin{center}
                    \includegraphics[width=0.8\textwidth]{figures/ai-definitions.png}
                    \caption[4 Definitionen AI]{4 Definitionen von AI, organisiert in 4 Kategorien nach \cite{russell}}
                    \label{pic:ai-definitions}
                \end{center}
            \end{figure}
            Der Turing Test beschäftigt sich größenteils mit der linken Seite des Spektrums, die rechte Seite erhält
            dahingegen wenig Beachtung durch den Turing Test. Dabei macht eine AI deutlich mehr aus, als so zu denken
            und zu handeln wie ein Mensch - es geht weit darüber hinaus.


        \subsection{Aktueller Forschungsstand bei AGI-Systems}
            Wie man bereits in \ref{pic:ai-definitions} erkennen kann, gibt es verschiedene Spektren der AI und der
            Definition für AIs. John Searle hat daher bereits 1980 mithilfe seines Gedankenexperiments die Behauptung
            aufgestellt, dass es zum aktuellen Zeitpunkt keine Strong AIs gibt. Dazu stelle man sich folgendes
            Gedankenexperiment vor, wonach man eine Maschine lediglich als ein Objekt sieht, welches Eingaben zu
            Ausgaben verarbeitet. \cite{cole_2014} Stellt man sich nun eine Maschine vor, welche mit gegebenen
            chinesischen Schriftzeichen eine solche Ausgabe erzeugt, dass ein chinesisch sprechender Mensch denkt,
            dass dies nicht von einer Maschine, sondern von einem Menschen verstanden und verarbeitet wurde, so könnte
            man das Experiment wiederholen, wobei man jedoch die Maschine und den Algorithmus zum Verarbeiten mit einem
            Menschen tauscht. Das sogenannte \textit{chinese room experiment} sagt aus, dass wenn Außenstehende glauben,
            dass in dem Raum ein chinesisch sprechender Mensch sitzt, es keine Strong AI geben kann. Da es demjenigen
            innerhalb des Raumes deutlich an Verständnis der chinesischen Sprache mangelt. git s


    \section{Safety Engineering}
        \subsection{Probleme bei AI Engineering}
        \subsection{AI Safety in klassischen AI Systems}
        \subsection{AI Safety in Artificial Superintelligent Systems}

        %% Eher nochmal bearbeiten:
        \subsection{Problemlösungsansätze}
        \subsection{Simulated Areas / Simulations}
    \section{The Artificial Confinementproblem}
        \subsection{Kritik des Confinement Approach}
        \subsection{Mögliche Escape Paths}
        \subsection{Social Engineering Attacks}
    \section{AI Boxing Strategies}
        \subsection{Physical Boxing}
        \subsection{Psychological Boxing}
        \subsection{Kombination mit anderen Limitierungstechniken}
    \section{Fazit}

    \newpage
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %% Einbinden der Quellen
    %% https://www.overleaf.com/learn/latex/Bibliography_management_with_bibtex#Reference_guide
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \addcontentsline{toc}{section}{\bibname}
    \bibliography{quellen}
    \bibliographystyle{dinat}

    \listoffigures

\end{document}
